---
title: "clana: Estatística Aplicada à Hidrometria"
author: "Juno Takano"
subtitle: "Aplicação de modelos de regressão múltipla para solução de dados faltantes em séries históricas de dados hidrométricos."
date: last-modified
lang: pt
language:
  title-block-author-single: "Por"
  title-block-published: "Última atualização"
format:
  html:
    css: assets/estilo.css
    df-print: paged
    theme: litera
    toc: true
    toc-depth: 5
    code-tools: 
      source: https://github.com/jultty/clana-esa
    code-block-bg: true
    code-block-border-left: "#31BAE9"
execute: 
  cache: true
---

![Gráfico de dispersão de um dos modelos abordados.](./assets/out/cotas04-03.png)

## Introdução

Este trabalho investiga a aplicabilidade de modelos de regressão múltipla no preenchimento de dados faltantes nas séries históricas de dados hidrométricos da Agência Nacional de Águas (ANA).

A ANA é uma entidade do governo brasileiro responsável pela realização de estudos, pesquisas, elaboração e fiscalização de normas reguladoras relacionadas aos recursos hídricos e ao saneamento básico (BRASIL, 2000).

A ANA disponibiliza dados através de um sistema público, o Sistema Nacional de Informações sobre Recursos Hídricos (SNIRH), onde é possível acessar medições de níveis fluviais, vazões, chuvas, clima, qualidade da água e sedimentos. As medições são coletadas por diferentes instituições e empresas ligadas à Rede Hidrometeorológica Nacional, coordenada pela ANA. Em 2018, a rede contava com 4641 pontos de monitoramento (“Portal HidroWeb”, 2023).

O principal conjunto de dados utilizado foi uma série histórica referente à estação de coleta de dados Jacareí  (Código 58110002), localizada no Rio Paraíba do Sul e operada pelo Serviço Geológico do Brasil. A série consiste de 962 observações ao longo dos anos 2000 a 2023.

A filtragem dos dados disponibilizados pelo termo "Jacareí" retornou um total de 33 resultados, tabulados abaixo por seus prefixos:

| Nº  | Categoria            | Arquivos |
|:---:|:---------------------|:--------:|
|  1  | chuvas               |    12    |
|  2  | cotas                |     5    |
|  3  | curvadescarga        |     2    |
|  4  | PerfilTransversal    |     2    |
|  5  | qualagua             |     3    |
|  6  | ResumoDescarga       |     4    |
|  7  | sedimentos           |     1    |
|  8  | vazoes               |     4    |
|**Σ**| **Total**            |  **33**  |

Em sua maior parte, tratam-se de dados de chuvas e cotas. O termo _cotas_ refere-se aos níveis de água dos rios (ANA, 2021).

As observações são distribuídas em 78 colunas, 62 delas para cada um dos 31 dias do mês e 31 informações de _status_ para o dia respectivo:

* **Cotas:** `Cota01` `Cota02` (...) `Cota30` `Cota31`

* **Status:** `Cota01Status` `Cota02Status` (...) `Cota30Status` `Cota31Status`

Antes destas 62 colunas, as primeiras 16 são:

* `EstacaoCodigo` `NivelConsistencia` `Data` `Hora` `MediaDiaria` `TipoMedicaoCotas` `Maxima` `Minima` `Media` `DiaMaxima` `DiaMinima` `MaximaStatus` `MinimaStatus` `MediaStatus` `MediaAnual` `MediaAnualStatus`

O significado de algumas destas variáveis é dado no topo de cada arquivo disponibilizado pelo sistema Hidroweb:

> NivelConsistencia: 1 = Bruto, 2 = Consistido  
> MediaDiaria: 0 = Não, 1 = Sim  
> TipoMedicaoCotas: 1 = Escala, 2 = Linígrafo, 3 = Data Logger  
> Status: 0 = Branco, 1 = Real, 2 = Estimado, 3 = Duvidoso, 4 = Régua Seca

Esta informação, que aparece antes dos dados estruturados, foi removida nos arquivos utilizados para análise neste trabalho, já que dificulta a leitura por ferramentas computacionais. O arquivo original foi preservado e acompanha os conjuntos processados.

Este relatório foi elaborado utilizando [R](https://www.r-project.org/) como ferramenta principal, uma linguagem de programação voltada à estatística. Para publicação, foi utilizado também o sistema de cadernos [Quarto](https://quarto.org/), parte do mesmo ecossistema.  

Parte dos conceitos utilizados foi desenvolvida paralelamente no trabalho [clana](https://github.com/jultty/clana), um estudo sobre Estruturas de Dados onde um outro conjunto da agência foi utilizado para o desenvolvimento de uma aplicação capaz de identificar e preencher lacunas usando modelos de regressão linear simples. 

## Visão geral

::: {.panel-tabset}

### Escopo do projeto

| | |
|-|-|
| **Objetivo** | Demonstrar a aplicabilidade de algoritmos de regressão linear múltipla na solução de dados faltantes em séries históricas de dados hidrométricos da Agência Nacional de Águas |
| **Problema** | Determinar programaticamente quais variáveis possuem correlações fortes |
| **Métrica** | Coeficiente de correlação |
| **Público**  | Pessoas pesquisadoras, estudantes e profissionais da área de hidrometria, geometeorologia e gestão de recursos hídricos |
| **Dados** | `cotas_C_58110002.csv` |

**Conjunto de dados utilizado:**

> AGÊNCIA NACIONAL DE ÁGUAS. cotas_C_58110002. Brasília, 2018. Disponível em: <https://www.snirh.gov.br/hidroweb/>. Acesso em: 29 jun. 2023

### Levantamento

#### Resultados da filtragem para Jacareí

| Código     | Estação                                     | Tipo de dado  |
|:----------:|:--------------------------------------------|:-------------:|
| `58110001` | JACAREÍ - RÉGUA DA MARGEM                   | Fluviométrica |
| `58110002` | JACAREÍ                                     | Fluviométrica |
| `58096000` | UHE SANTA BRANCA JUSANTE                    | Fluviométrica |
| `58110000` | UHE SANTA BRANCA JACAREÍ                    | Fluviométrica |
| `58044000` | BAIRRO RIO COMPRIDO                         | Fluviométrica |
| `58138000` | BAIRRO REMEDINHO                            | Fluviométrica |
| `58110010` | JACAREÍ                                     | Fluviométrica |
| `58138500` | PTE. ACESSO RES. JAQUARI (próx. Brahma)     | Fluviométrica |
                                                                       
:::

O coeficiente de correlação, aqui obtido programaticamente para encontrar relações fortes entre as diferentes variáveis, foi utilizado como a métrica norteadora deste estudo através de uma matriz de correlação.

## Carregamento

Nesta etapa, os dados foram carregados e preparados para o processamento.

O arquivo de dados original é disponibilizado no formato **csv**, com vírgulas separando casas decimais e ponto e vírgula separando as colunas.

Serão utilizadas as bibliotecas `tidyverse` e `janitor` para limpar e fazer o processamento inicial dos dados:

```{r}
#| output: false

library(tidyverse)
library(janitor)
```

O termo **cotas** foi adotado para referir-se ao conjunto de dados no código.

```{r importa os dados}
cotas <- read_delim("dados/cotas_C_58110002_headless.csv", delim=";")
```

## Limpeza

Pela saída da importação é possível ver que há problemas. A mesma mensagem indica como listá-los:

```{r}
problems(cotas)
```

Parece que cada linha é terminada com um caracter `;` extra.

Será portanto necessário limpar este caracter da última coluna e alterar o tipo para numérico: 

```{r}
cotas$Cota31Status <- as.numeric(gsub(";$", "", cotas$Cota31Status))
```

O conjunto carregado agora possui uma estrutura uniforme, ainda que com muitas lacunas:

```{r}
#| code-fold: true

cotas |> 
  filter(
    grepl("01/04/2022", Data)
  )
```
Acima, uma filtragem demonstrativa das observações referentes ao mês de abril de 2022.

### Cabeçalhos

Os cabeçalhos do arquivo original foram processados automaticamente, e não possuem caracteres especiais ou espaços:

```{r}
colnames(cotas)
```

Não foi necessária qualquer limpeza e eles puderam ser mantidos como no original, o que trouxe facilidade na verificação cruzada com o conjunto original e ferramentas auxiliares tais como planilhas.

## Análise

Abaixo obteve-se uma listagem de quantas lacunas há em cada coluna:

```{r}
#| code-fold: true

# obtém a quantidade de entradas nulas em cada coluna 
total_lacunas <- colSums(is.na(cotas))

# filtra colunas sem valores nulos
total_lacunas <- total_lacunas[total_lacunas > 0]

# ordena os resultados de forma decrescente 
total_lacunas <- total_lacunas[order(total_lacunas, decreasing = TRUE)]

as_tibble(
 enframe(total_lacunas, name = "column", value = "n"))
```

### Correlação

Usando a função `cor()` é possível chegar a uma matriz de coeficientes de correlação entre cada variável:

```{r}
#| code-fold: true
#| warning: false
#| error: false
# TODO: Considerar o desvio padrão

library(dplyr)
library(Matrix)

matriz <- cotas |>
  select_if(is.numeric) |>
  cor(use = "pairwise.complete.obs") |>
  as_tibble() 

matriz |>
  add_column(Coluna = colnames(cotas)
    [sapply(cotas, is.numeric)], .before = 1)
```

A matriz de correlação obtida acima usa um método de correlação em pares para a covariância, parâmetro que indica o grau de interdependência linear entre duas variáveis em relação às suas médias. 

Com a opção `pairwise.complete.obs`, são considerados apenas os pares onde nenhum dos dois valores é nulo. Como desvantagem, ela pode reduzir demais o tamanho da amostra quando há uma quantidade grande de valores nulos. 

Temos agora valores nulos apenas para as colunas e linhas onde todos os valores eram nulos originalmente. Para removê-los:

```{r}
#| warning: false

matriz <- remove_empty(matriz)
```

A documentação do pacote _stats_, ao qual pertence a função `cor()` utilizada acima, explica especificamente sobre a opção de completação de lacunas em pares:

> "[for `pairwise.complete.obs`] the correlation or covariance between each pair of variables is computed using all complete pairs of observations on those variables. This can result in covariance or correlation matrices which are not positive semi-definite, as well as NA entries if there are no complete pairs for that pair of variables." (R CORE TEAM, 2019)

### Validação do instrumento

A documentação também menciona que esta opção, em tradução livre, _"pode resultar em matrizes de covariância ou correlação que **não são positivas semi-definidas**"_, o que tem implicações que prejudicam a aplicabilidade da matriz na análise estatística.

Para compreender melhor o conceito de uma matriz positiva semi-definida (PSD) e aferir o efeito da escolha do método `pairwise.complete.obs`, foram utilizados duas técnicas de decomposição para verificar se a matriz é ou não uma matriz PSD.

#### Método de decomposição de autovalores

```{r}
#| code-fold: true
matriz_tipada <- as.matrix(matriz)
autovalores <- eigen(matriz_tipada)$values

if(all(autovalores >= 0)) {
  print("A matriz é PSD")
} else {
  print("A matriz não é PSD")
}
```

#### Método de decomposição de Cholesky

```{r}
#| code-fold: true
triangular_inferior <- tryCatch(chol(matriz), error = function(e) NULL)

if(is.null(triangular_inferior)) {
  print("A matriz não é PSD")
} else {
  if(all.equal(matriz, crossprod(triangular_inferior))) {
    print("A matriz é PSD")
  }
}
```

Os resultados mostram que a matriz obtida não é positiva semi-definida. Testes com a opção `na.or.complete` também não resultaram em uma matriz PSA.

Observando a matriz de autovalores, temos:

```{r}
eigen(matriz)$values
```

Parece que os autovalores negativos estão todos após a posição 62.

### Recorte

Foi realizado um recorte utilizando apenas os dados referentes às cotas de cada 31 dias:

```{r}
#| code-fold: true

recorte <- cotas |>
  select(Cota01:Cota31) |>
  drop_na()
 
recorte
```

Em seguida, o recorte foi limpo de colunas ou linhas contendo campos vazios.

```{r}
#| code-fold: true

matriz_recorte <- recorte |>
  select_if(is.numeric) |>
  cor(use = "na.or.complete") |>
  as_tibble() 

matriz_recorte
```

A recontagem de valores nulos mostra que não restaram mais lacunas:

```{r}
#| code-fold: true

# obtém a quantidade de entradas nulas em cada coluna 
lacunas <- colSums(is.na(matriz_recorte))

# filtra colunas sem valores nulos
lacunas <- lacunas[lacunas > 0]

# ordena os resultados de forma decrescente 
lacunas <- lacunas[order(lacunas, decreasing = TRUE)]

as_tibble(enframe(lacunas, name = "column", value = "n"))
```

#### Método de decomposição de autovalores

O novo recorte foi testado com sucesso pela decomposição de autovalores:

```{r}
#| code-fold: true
tryCatch( autovalores <- eigen(matriz_recorte)$values , error = function(e) NULL)

if(is.null(autovalores)) {
  print("Erro:")
  print(e)
} else {
  if(all(autovalores >= 0)) {
    print("A matriz é PSD")
  } else {
    print("A matriz não é PSD")
  }
}
```

Embora com este recorte seja possível um resultado positivo usando a técnica de verificação pela decomposição de autovalores, o fato da matriz não ser simétrica torna impossível realizar a segunda etapa necessária ao teste de decomposição de Cholesky.

O teste abaixo verifica se a matriz é simétrica:

```{r}
#| code-fold: true
matriz_recorte <- as.matrix(matriz_recorte)

if (isSymmetric(matriz_recorte)) {
  print("A matriz é simétrica")
} else {
  print("A matriz não é simétrica")
}
```

Uma solução para o problema é completar a forma simétrica da matriz pela sua transposta.

#### Método de decomposição de Cholesky com a matriz completada

```{r}
#| code-fold: true

# obtém a matriz simétrica somando-a com a transposta e dividindo por 2
matriz_simetrica <- (matriz_recorte + t(matriz_recorte)) / 2
triangular_inferior <- tryCatch(chol(matriz_simetrica), error = function(e) NULL)

triangular_superior <- row(triangular_inferior) > col(triangular_inferior)
all(triangular_inferior[triangular_superior] == 0)

```

Foram levantados ainda os seguintes testes adicionais, que também confirmaram a matriz como PSD:

#### Teste por decomposição em valores singulares 

```{r}
#| code-fold: true
decomposicao <- svd(matriz_recorte)
all(decomposicao$d >= 0)
```

#### Teste pela forma quadrática 

```{r}
#| code-fold: true
n_colunas = ncol(matriz_recorte)

x <- sample(-9:9, n_colunas, replace = TRUE)

while (all(x == 0)) {  
  x <- sample(-9:9, n_colunas, replace = TRUE)
}

resultado <- TRUE
for (i in 1:n_colunas) {
  if (t(x) %*% matriz_recorte %*% x < 0) {
    resultado <- FALSE
    break
  }
}

resultado
```

## Aplicação

Utilizando esta região, podemos fitlrar o conjunto original para ver como ela é incluindo suas lacunas.

```{r}
#| code-fold: true

cotas |>
  select(Cota01:Cota31)
```

Podemos encontrar diversas áreas onde o modelo desenvolvido pode ser testado. Por exemplo, a região abaixo:

```{r}
#| code-fold: true

cotas |> 
  select(Cota05:Cota16) |>
  slice(745:755)
```

Esta região corresponde aos dias 7 a 12 de abril de 2022.

Na tabela abaixo, vemos a mesma matriz de correlação com uma coluna extra à frente que facilita verificar a correlação entre as observações mostradas no intervalo.

```{r}
#| code-fold: true

matriz_df <- matriz_recorte |>
  as.data.frame()

matriz_df |>
  add_column(Colunas = colnames(matriz_recorte), .before = 1)
```

#### Modelo demonstrativo

Usando a função nativa em R para criar modelos de regressão linear, podemos criar um modelo utilizando duas ou mais variáveis. Para a coluna 7, podemos usar as colunas completas mais próximas, 6 e 5, que possuem coeficientes de correlação maiores.

```{r}
#| code-fold: true

model = lm(Cota07~Cota06 + Cota05, data = matriz_df)
```

O modelo retornado contém diferentes parâmetros para esta correlação específica:
```{r}
#| echo: false
summary(model) 
```

É possível destacar, por exemplo, os coeficientes:
```{r}
#| echo: false
coefficients(model)
```

E $r^2$ para a correlação múltipla entre as variáveis `Cota07`, `Cota06` e `Cota05`:
```{r}
#| echo: false
summary(model)$r.squared
```

```{r}
#| code-fold: true
#| fig-cap: Plotagem para a correlação entre Cota07 e Cota06.  As variáveis apresentaram uma correlação positiva de 87%

library(ggplot2)

ggplot(matriz_df, aes(x = Cota07, y = Cota06)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "darkgreen") +
  labs(x = "Cota 07", y = "Cota 06") +
  annotate("text", x = max(matriz_df$Cota07), y = max(matriz_df$Cota06),
  label = paste("r:", round(cor(matriz_df$Cota07, matriz_df$Cota06), 2)),
  hjust = 1, vjust = 1)
```

```{r}
#| code-fold: true
#| fig-cap: Plotagem demonstrativa para uma entre duas medições distantes, Cota01 e Cota07. A correlação encontrada foi de apenas 43%

library(ggplot2)

ggplot(matriz_df, aes(x = Cota07, y = Cota01)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "darkgreen") +
  labs(x = "Cota 07", y = "Cota 01") +
  annotate("text", x = max(matriz_df$Cota07), y = max(matriz_df$Cota01),
  label = paste("r:", round(cor(matriz_df$Cota07, matriz_df$Cota01), 2)),
  hjust = 1, vjust = 1)
```

```{r}
#| code-fold: true
#| fig-cap: Dispersão para Cota03 e Cota04, com correlação de 99%, uma das maiores encontradas na matriz de correlação. Os padrões observáveis na matriz mostram que medições em dias próximos exibem um padrão linear de mudança.

library(ggplot2)

ggplot(matriz_df, aes(x = Cota03, y = Cota04)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "darkgreen") +
  labs(x = "Cota 03", y = "Cota 04") +
  annotate("text", x = max(matriz_df$Cota03), y = max(matriz_df$Cota04),
  label = paste("r:", round(cor(matriz_df$Cota03, matriz_df$Cota04), 2)),
  hjust = 1, vjust = 1)
```

## Conclusão

Para cenários onde os níveis dos rios não passam por mudanças bruscas, a regressão linear pode ser um instrumento eficaz na previsão de valores faltantes, em especial onde há dados em dias contíguos que podem ser usados na construção do modelo.

Como o estudo tomou como principal métrica os coeficientes de correlação, numericamente os dados mais sintéticos sobre o que foi observado estão na matriz de correlação obtida:

```{r}
#| echo: false

matriz_df
```

Os dados mostram uma tendência visível que varia de mais para menos conforme a variável se distancia da data em que o valor observado de fato ocorreu. 

Embora neste recorte específico possamos perceber uma tendência relativamente linear, cabe ressaltar que diferentes fatores podem afetar as cotas, alguns linearmente relacionados e outros não, como a precipitação em pontos distantes que chegam aos rios por escoamento superficial e subterrâneo (CHOW et al., 1994 apud CAPOZZOLI et al., 2017).

As ferramentas utilizadas podem ser readaptadas para diferentes intervalos e tipos de conjuntos com poucas adaptações. Com isto a contribuição na criação de modelos documentáveis e transparentes também aparece como uma possibilidade interessante.

## Bibliografia

- AGÊNCIA NACIONAL DE ÁGUAS. Sistema Hidroweb - Séries históricas. Brasília, 2018. Disponível em: <https://www.snirh.gov.br/hidroweb/>. Acesso em: 29 jun. 2023
- AGÊNCIA NACIONAL DE ÁGUAS. Levantamentos topobatimétricos e geodésicos aplicados na Rede Hidrometeorológica Nacional. Brasília, 2021. Disponível em: <https://www.gov.br/ana/pt-br/assuntos/monitoramento-e-eventos-criticos/monitoramento-hidrologico/orientacoes-manuais/documentos/manual-de-nivelamento>. Acesso em: 29 jun. 2023
- GUZMÁN, N. G. Modelagem para estimativa de dados faltantes em série de dados meteorológicos. Dissertação (Mestrado em Modelagem Computacional) — Nova Friburgo: Universidade do Estado do Rio de Janeiro, 5 abr. 2018.
- BRASIL. Poder Executivo. Lei Nº 9.984, de 17 de julho de 2000. Dispõe sobre a criação da Agência Nacional de Águas e Saneamento Básico. Brasília, DF: Poder Executivo, 2000. Disponível em: <http://www.planalto.gov.br/ccivil_03/leis/l9984.htm>
- R CORE TEAM. R: A language and environment for statistical computing. Vienna, Áustria. R Foundation for Statistical Computing, 2018. Disponível em: <https://www.R-project.org/>. Acesso em: 29 jun. 2023
- ALLAIRE, J. J. et al. Quarto. 23 jun. 2023. Disponível em: <https://quarto.org/>
- R CORE TEAM. cor: Correlation, Variance and Covariance (Matrices). Disponível em: <https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/cor>. Acesso em: 1 jul. 2023. 
- CAPOZZOLI, C. R.; CARDOSO, A. DE O.; FERRAZ, S. E. T. Padrões de Variabilidade de Vazão de Rios nas Principais Bacias Brasileiras e Associação com Índices Climáticos. Revista Brasileira de Meteorologia, v. 32, p. 243–254, jun. 2017. 


* Recursos relacionados 
  * [Portal de Dados Abertos da ANA](https://dados.ana.gov.br/)
  * [Sistema Nacional de Informações sobre Recursos Hídricos](https://www.snirh.gov.br/)
  * [Hidroweb v3.2.7](https://www.snirh.gov.br/hidroweb/apresentacao)
  * [Serviço Geológico do Brasil: Hidrologia](http://www.cprm.gov.br/publique/Hidrologia/Apresentacao-364)
  * [Rede Hidrometeorológica Nacional - RHN](http://www.cprm.gov.br/publique///Apresentacao/Rede-Hidrometeorologica-Nacional---RHN-304.html)

